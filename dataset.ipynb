{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a83b586d-4c77-49ee-a872-64a600f8ad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcb27d95-bb1f-4d3b-9b99-29b83f5ede8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36e28824-6686-48a2-a73d-fa7a99a47053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/raw/Flickr2K\n"
     ]
    }
   ],
   "source": [
    "FILE_PATH = Path('data/raw/Flickr2K')\n",
    "print(FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b2801d9-4ef1-4bf0-8c1e-f796dd735d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "HR_SIZE = 128\n",
    "SCALE = 2\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d67e9e3-a824-4289-b05c-1b28d3536201",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "files.extend(FILE_PATH.rglob('*.jpg'))\n",
    "files.extend(FILE_PATH.rglob('*.png'))\n",
    "files = sorted(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a2f68f4-d972-4277-8abd-b516344ff715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2650\n"
     ]
    }
   ],
   "source": [
    "print (len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f16d556c-6d3b-4697-b0ac-8f315dbfdfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c857cf4c-e157-4957-ab9e-0d5bb80036f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2650\n",
      "[PosixPath('data/raw/Flickr2K/000001.png'), PosixPath('data/raw/Flickr2K/000002.png'), PosixPath('data/raw/Flickr2K/000003.png')]\n",
      "<class 'pathlib.PosixPath'>\n"
     ]
    }
   ],
   "source": [
    "print(len(files))\n",
    "print(files[:3])\n",
    "print(type(files[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a46c600a-a902-4a6d-a42e-c76b46b839e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d7a8957-3b70-4d19-9c89-58bb6b75efa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e684b145-cde2-480c-b281-19cd49b0f051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('data/raw/Flickr2K/001583.png'), PosixPath('data/raw/Flickr2K/001605.png'), PosixPath('data/raw/Flickr2K/000279.png'), PosixPath('data/raw/Flickr2K/002041.png'), PosixPath('data/raw/Flickr2K/000187.png'), PosixPath('data/raw/Flickr2K/001694.png'), PosixPath('data/raw/Flickr2K/002460.png'), PosixPath('data/raw/Flickr2K/002077.png'), PosixPath('data/raw/Flickr2K/001197.png'), PosixPath('data/raw/Flickr2K/000340.png')]\n"
     ]
    }
   ],
   "source": [
    "print(files[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db55bbbd-7a84-47d3-8cff-0ee0b5f62643",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = files[:2120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5a776ec-670a-4936-a5e8-cf57bd949d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2120"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c390aa23-52cb-4101-9faf-46d77e2717d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_files = files[2120:2120+265]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2df9ab5-8a75-4be0-afe9-221c7a46f9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_files)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a036aaaf-8f3a-471f-8e36-6a588bfbdb1a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19fd84e2-3c94-4686-a604-12b17374a5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = files[2120+265:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dce65b59-7d56-46d5-8a82-3299023b68c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a60c166-88b0-4d46-bccb-bb8e390e8e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/raw/Flickr2K/001583.png <class 'pathlib.PosixPath'>\n"
     ]
    }
   ],
   "source": [
    "print(train_files[0],type(train_files[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d07d7607-6912-4b63-8126-ffaf860bb2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FixedLenFeature',\n",
       " 'FixedLenSequenceFeature',\n",
       " 'RaggedFeature',\n",
       " 'SparseFeature',\n",
       " 'TFRecordOptions',\n",
       " 'TFRecordWriter',\n",
       " 'VarLenFeature',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_sys',\n",
       " 'decode_and_crop_jpeg',\n",
       " 'decode_base64',\n",
       " 'decode_bmp',\n",
       " 'decode_compressed',\n",
       " 'decode_csv',\n",
       " 'decode_gif',\n",
       " 'decode_image',\n",
       " 'decode_jpeg',\n",
       " 'decode_json_example',\n",
       " 'decode_png',\n",
       " 'decode_proto',\n",
       " 'decode_raw',\n",
       " 'decode_webp',\n",
       " 'deserialize_many_sparse',\n",
       " 'encode_base64',\n",
       " 'encode_jpeg',\n",
       " 'encode_png',\n",
       " 'encode_proto',\n",
       " 'extract_jpeg_shape',\n",
       " 'gfile',\n",
       " 'is_jpeg',\n",
       " 'match_filenames_once',\n",
       " 'matching_files',\n",
       " 'parse_example',\n",
       " 'parse_sequence_example',\n",
       " 'parse_single_example',\n",
       " 'parse_single_sequence_example',\n",
       " 'parse_tensor',\n",
       " 'read_file',\n",
       " 'serialize_many_sparse',\n",
       " 'serialize_sparse',\n",
       " 'serialize_tensor',\n",
       " 'write_file',\n",
       " 'write_graph']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tf.io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "099436b9-d885-4846-b88b-7efe32b2c35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "\n",
    "    tf_read = tf.io.read_file(path)\n",
    "    tf_img_decode = tf.image.decode_image(tf_read,channels = 3, expand_animations = False)\n",
    "    tf_img_float = tf.image.convert_image_dtype(tf_img_decode, tf.float32)\n",
    "    img.set_shape([None,None,3])\n",
    "\n",
    "    return tf_img_float\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce4850d3-ee77-4f78-b1de-5d67237349b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'pathlib.PosixPath'>\n",
      "data/raw/Flickr2K/001583.png\n"
     ]
    }
   ],
   "source": [
    "print(type(train_files))\n",
    "print(type(train_files[0]))\n",
    "print(train_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d86c8aac-813e-40b6-9e9b-72a147801914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> <class 'pathlib.PosixPath'> data/raw/Flickr2K/001583.png\n"
     ]
    }
   ],
   "source": [
    "print(type(files), type(files[0]), files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f4d369ad-6e53-4de6-91f4-d04aa2aa2a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1356, 2040, 3)\n",
      "<dtype: 'float32'>\n",
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "img = load_image(str(train_files[0]))\n",
    "print(img.shape)\n",
    "print(img.dtype)\n",
    "print(float(tf.reduce_min(img)), float(tf.reduce_max(img)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b3091350-c0c0-4ee8-b338-5fa3e55f3f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hr_patch(img,hr_size):\n",
    "    shape = tf.shape(img)\n",
    "    h = shape[0]\n",
    "    w = shape[1]\n",
    "\n",
    "    condition = tf.logical_or(h < hr_size, w< hr_size)\n",
    "    \n",
    "    def resize_img():\n",
    "        new_h = tf.maximum(h,hr_size)\n",
    "        new_w = tf.maximum(w,hr_size)\n",
    "        \n",
    "        new_img = tf.image.resize(img, size =[new_h,new_w], method = 'bilinear')\n",
    "        return new_img\n",
    "        \n",
    "    def no_resize():\n",
    "        return img\n",
    "\n",
    "    img = tf.cond(condition,resize_img,no_resize)\n",
    "\n",
    "    hr_patch = tf.image.random_crop(img, size=[hr_size,hr_size,3])\n",
    "    return hr_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb57f0d0-8457-4f92-b89e-b45de5df2369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 3)\n",
      "<dtype: 'float32'>\n",
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "img = load_image(str(train_files[0]))\n",
    "hr = make_hr_patch(img, 128)\n",
    "print(hr.shape)\n",
    "print(hr.dtype)\n",
    "print(float(tf.reduce_min(hr)), float(tf.reduce_max(hr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cd14264e-bfe6-41fa-8d04-4ae79a404046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lr_patch(hr, scale):\n",
    "    h = tf.shape(hr)[0]\n",
    "    w = tf.shape(hr)[1]\n",
    "\n",
    "    new_h = h // scale\n",
    "    new_w = w// scale\n",
    "\n",
    "    lr_small = tf.image.resize(hr,size = [new_h,new_w], method = 'bicubic')\n",
    "    lr_small = tf.clip_by_value(lr_small, 0.0, 1.0)\n",
    "\n",
    "    return lr_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9398997a-15ff-468f-b5cd-27b02184b50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 3) (64, 64, 3)\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "img = load_image(str(train_files[0]))\n",
    "hr = make_hr_patch(img, 128)\n",
    "lr = make_lr_patch(hr, 2)\n",
    "\n",
    "print(hr.shape, lr.shape)\n",
    "print(float(tf.reduce_max(lr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fe9869b4-db1a-4488-88d7-4153925ac14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pair(path,hr_size,scale):\n",
    "    img = load_image(path)\n",
    "    hr = make_hr_patch(img, hr_size)\n",
    "    lr = make_lr_patch(hr,scale)\n",
    "\n",
    "    return lr,hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ab316026-74c6-4ada-9e48-300111af1214",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr, hr = make_pair(str(train_files[0]),128,2)\n",
    "#print(lr.shape, hr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9c894453-ad3b-4918-a17b-003e4ee9d2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_paths = [str(p) for p in train_files[:200]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1a388b45-c7c1-421f-93c9-65118aa9b6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds = tf.data.Dataset.from_tensor_slices(train_paths)\n",
    "#def exists_tf(path):\n",
    "#    return tf.io.gfile.exists(path)\n",
    "\n",
    "#ds = ds.map(make_pair, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f2cfaaf4-189f-4faa-a62e-d4534a96d61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(next(iter(ds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8055a36e-5ca6-4218-aedc-a7a4b23211e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#element = next(iter(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c6de45f2-6217-4d9e-a488-6bf52f4380db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr, hr = element\n",
    "#print(\"LR:\", lr.shape)\n",
    "#print(\"HR:\", hr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f75675fd-b424-4347-971b-d362a41784d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##IDEMO BREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "80a7d03b-484f-4229-94b5-866ad44ef40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sr_dataset(paths,hr_size,scale,batchs_size,training):\n",
    "    shuffle_buffer = 1000\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices(paths)\n",
    "    \n",
    "    if training:\n",
    "        ds = ds.shuffle(shuffle_buffer,reshuffle_each_iteration = True)\n",
    "\n",
    "    ds= ds.map(lambda p: make_pair(p,hr_size,scale),num_parallel_calls = tf.data.AUTOTUNE)\n",
    "\n",
    "    if training:\n",
    "        ds = ds.batch(batchs_size,drop_remainder = True)\n",
    "    else:\n",
    "        ds = ds.batch(batchs_size,drop_remainder = False)\n",
    "\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        \n",
    "    return ds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "054da7b8-b093-479c-a4b7-268a7074f36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_input_dataset': <_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>,\n",
       " '_use_inter_op_parallelism': True,\n",
       " '_map_func': <tensorflow.python.data.ops.structured_function.StructuredFunctionWrapper at 0x1482f5d10>,\n",
       " '_deterministic': 'default',\n",
       " '_preserve_cardinality': True,\n",
       " '_num_parallel_calls': <tf.Tensor: shape=(), dtype=int64, numpy=-1>,\n",
       " '_use_unbounded_threadpool': False,\n",
       " '_name': None,\n",
       " '_variant_tensor_attr': <tf.Tensor: shape=(), dtype=variant, value=<ParallelMapDatasetV2Op::Dataset>>,\n",
       " '_graph_attr': <tensorflow.python.framework.ops.Graph at 0x1090a8e40>,\n",
       " '_options_attr': <tensorflow.python.data.ops.options.Options at 0x14c3ab6d0>}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856fb1fa-de3d-4b92-9170-456ef08b9c66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68723bfd-ec92-47a5-a75c-5cc6858dfb0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf311)",
   "language": "python",
   "name": "tf311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
